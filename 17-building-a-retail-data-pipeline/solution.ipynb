{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution code\n",
    "\n",
    "# Paste the following SQL query into the SQL code cell without the leading # symbol:\n",
    "# SELECT * FROM grocery_sales\n",
    "\n",
    "\n",
    "# Paste the following Python code into the Python code cell:\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# extract functin is already implemented for you \n",
    "def extract(store_data, extra_data):\n",
    "    extra_df = pd.read_parquet(extra_data)\n",
    "    merged_df = store_data.merge(extra_df, on = \"index\")\n",
    "    return merged_df\n",
    "\n",
    "# Call the extract() function and store it as the \"merged_df\" variable\n",
    "merged_df = extract(grocery_sales, \"extra_data.parquet\")\n",
    "\n",
    "# Create the transform() function with one parameter: \"raw_data\"\n",
    "def transform(raw_data):\n",
    "  # Fill NaNs using mean since we are dealing with numeric columns\n",
    "  # Set inplace = True to do the replacing on the current DataFrame\n",
    "    raw_data.fillna(\n",
    "      {\n",
    "          'CPI': raw_data['CPI'].mean(),\n",
    "          'Weekly_Sales': raw_data['Weekly_Sales'].mean(),\n",
    "          'Unemployment': raw_data['Unemployment'].mean(),\n",
    "      }, inplace = True\n",
    "    )\n",
    "\n",
    "    # Define the type of the \"Date\" column and its format\n",
    "    raw_data[\"Date\"] = pd.to_datetime(raw_data[\"Date\"], format = \"%Y-%m-%d\")\n",
    "    # Extract the month value from the \"Date\" column to calculate monthly sales later on\n",
    "    raw_data[\"Month\"] = raw_data[\"Date\"].dt.month\n",
    "\n",
    "    # Filter the entire DataFrame using the \"Weekly_Sales\" column. Use .loc to access a group of rows\n",
    "    raw_data = raw_data.loc[raw_data[\"Weekly_Sales\"] > 10000, :]\n",
    "    \n",
    "    # Drop unnecessary columns. Set axis = 1 to specify that the columns should be removed\n",
    "    raw_data = raw_data.drop([\"index\", \"Temperature\", \"Fuel_Price\", \"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\", \"Type\", \"Size\", \"Date\"], axis = 1)\n",
    "    return raw_data\n",
    "\n",
    "# Call the transform() function and pass the merged DataFrame\n",
    "clean_data = transform(merged_df)\n",
    "\n",
    "# Create the avg_weekly_sales_per_month function that takes in the cleaned data from the last step\n",
    "def avg_weekly_sales_per_month(clean_data):\n",
    "  \t# Select the \"Month\" and \"Weekly_Sales\" columns as they are the only ones needed for this analysis\n",
    "    holidays_sales = clean_data[[\"Month\", \"Weekly_Sales\"]]\n",
    "   \t# Create a chain operation with groupby(), agg(), reset_index(), and round() functions\n",
    "    # Group by the \"Month\" column and calculate the average monthly sales\n",
    "    # Call reset_index() to start a new index order\n",
    "    # Round the results to two decimal places\n",
    "    \n",
    "    holidays_sales = (holidays_sales.groupby(\"Month\")\n",
    "    .agg(Avg_Sales = (\"Weekly_Sales\", \"mean\"))\n",
    "    .reset_index().round(2))\n",
    "    return holidays_sales\n",
    "\n",
    "# Call the avg_weekly_sales_per_month() function and pass the cleaned DataFrame\n",
    "agg_data = avg_weekly_sales_per_month(clean_data)\n",
    "\n",
    "# Create the load() function that takes in the cleaned DataFrame and the aggregated one with the paths where they are going to be stored\n",
    "def load(full_data, full_data_file_path, agg_data, agg_data_file_path):\n",
    "  \t# Save both DataFrames as csv files. Set index = False to drop the index columns\n",
    "    full_data.to_csv(full_data_file_path, index = False)\n",
    "    agg_data.to_csv(agg_data_file_path, index = False)\n",
    "\n",
    "# Call the load() function and pass the cleaned and aggregated DataFrames with their paths    \n",
    "load(clean_data, \"clean_data.csv\", agg_data, \"agg_data.csv\")\n",
    "\n",
    "# Create the validation() function with one parameter: file_path - to check whether the previous function was correctly executed\n",
    "def validation(file_path):\n",
    "  \t# Use the \"os\" package to check whether a path exists\n",
    "    file_exists = os.path.exists(file_path)\n",
    "    # Raise an exception if the path doesn't exist, hence, if there is no file found on a given path\n",
    "    if not file_exists:\n",
    "        raise Exception(f\"There is no file at the path {file_path}\")\n",
    "\n",
    "# Call the validation() function and pass first, the cleaned DataFrame path, and then the aggregated DataFrame path\n",
    "validation(\"clean_data.csv\")\n",
    "validation(\"agg_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-engineer-in-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
